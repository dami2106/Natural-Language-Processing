{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e35adf4c-2632-4c84-a35c-3c8e152469c7",
      "metadata": {
        "id": "e35adf4c-2632-4c84-a35c-3c8e152469c7"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import initializers\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import scipy.sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1d4c9000",
      "metadata": {},
      "outputs": [],
      "source": [
        "books = [1]\n",
        "window_size = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "882aca16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "882aca16",
        "outputId": "999ef130-8690-427e-893a-2ba1f1797c5d"
      },
      "outputs": [],
      "source": [
        "book_text = \"\"\n",
        "\n",
        "for book in books:\n",
        "  with open (f\"harry_potter/HP{book}.txt\", 'r') as f:\n",
        "      data = str(f.read()).lower()\n",
        "      book_text += data + ' '\n",
        "      f.close()\n",
        "\n",
        "formatted = re.compile(r'[A-Za-z]+[\\w^\\']*|[\\w^\\']*[A-Za-z]+[\\w^\\']*')\n",
        "formatted = formatted.findall(book_text.lower())\n",
        "book_text = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b1db9d20-9b9c-4338-aa84-6633099665fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1db9d20-9b9c-4338-aa84-6633099665fc",
        "outputId": "c7ec075e-818d-45aa-b6e6-5be168f7d727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size : 5729\n",
            "Total length of corpus : 80591\n"
          ]
        }
      ],
      "source": [
        "unique_words = np.unique(formatted)\n",
        "dict_size = len(unique_words)\n",
        "corpus_size = len(formatted)\n",
        "print(f\"Vocab size : {dict_size}\\nTotal length of corpus : {corpus_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5e7759ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "encoding_to_word = {}\n",
        "word_to_encoding = {}\n",
        "\n",
        "for i, word in enumerate(unique_words):\n",
        "    encoding_to_word[i] = word\n",
        "    word_to_encoding[word] = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e6ce7efd",
      "metadata": {},
      "outputs": [],
      "source": [
        "window = [i for i in range(-window_size, window_size + 1) if i != 0]\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for i in range(corpus_size):\n",
        "    for j in window:\n",
        "        if i + j >= 0 and i + j < corpus_size:\n",
        "            data_enc = np.zeros(dict_size)\n",
        "            labels_enc = np.zeros(dict_size)\n",
        "            data_enc[word_to_encoding[formatted[i]]] = 1\n",
        "            labels_enc[word_to_encoding[formatted[i + j]]] = 1\n",
        "            data.append(data_enc)\n",
        "            labels.append(labels_enc)\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "126797aa",
      "metadata": {
        "id": "126797aa"
      },
      "outputs": [],
      "source": [
        "embedding_size = 300\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=embedding_size,\n",
        "                          activation='linear',\n",
        "                          input_shape=(dict_size,),\n",
        "                          name='hidden_1'),\n",
        "    # Modify the Reshape layer to reshape the output to (None, embedding_size)\n",
        "    tf.keras.layers.Reshape((embedding_size,), name='reshape'),\n",
        "    tf.keras.layers.Dense(units=dict_size,\n",
        "                          activation='softmax',\n",
        "                          name='output')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92541ec8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92541ec8",
        "outputId": "6ea7beb7-02dc-4581-c08f-c27352602f63"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56897203",
      "metadata": {
        "id": "56897203"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.05)\n",
        "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f4dcbbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f4dcbbf",
        "outputId": "fc10147f-a797-4252-a504-aa51a17e9a1f"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "model.fit(datagen, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5VjTGcBunvjx",
      "metadata": {
        "id": "5VjTGcBunvjx"
      },
      "outputs": [],
      "source": [
        "def get_embedding(model, input_word):\n",
        "    hidden_layer_model = Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "    hidden_output = hidden_layer_model.predict(np.array([encoding_mapping[input_word]]), verbose = 0)\n",
        "    return hidden_output[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EmoqQtO0n9Nd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmoqQtO0n9Nd",
        "outputId": "15c8e218-b9a5-4ea0-f465-29b8c19e2f8c"
      },
      "outputs": [],
      "source": [
        "embedding_collection = {}\n",
        "\n",
        "for word in unique_words:\n",
        "  embedding_collection[word] = get_embedding(model, word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ewPx2YspXd2",
      "metadata": {
        "id": "5ewPx2YspXd2"
      },
      "outputs": [],
      "source": [
        "#Find the word most similar to \"water\"\n",
        "min_dist = np.linalg.norm(embedding_collection[\"water\"] - embedding_collection[\"after\"])\n",
        "min_word = \"after\"\n",
        "for word in unique_words:\n",
        "  if word != \"water\" and word != \"after\":\n",
        "    min_dist = min(min_dist, np.linalg.norm(embedding_collection[\"water\"] - embedding_collection[word]))\n",
        "    min_word = word\n",
        "\n",
        "min_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e_TUgxrvsDcH",
      "metadata": {
        "id": "e_TUgxrvsDcH"
      },
      "outputs": [],
      "source": [
        "# #Get the most similar word to every other word\n",
        "# for i in range(len(unique_words)):\n",
        "#   min_dist = np.infty\n",
        "#   min_word = \"\"\n",
        "#   for j in range(len(unique_words)):\n",
        "#     if j != i:\n",
        "#       new_min = np.linalg.norm(embedding_collection[unique_words[i]] - embedding_collection[unique_words[j]])\n",
        "\n",
        "#       if new_min <= min_dist:\n",
        "#         min_dist = new_min\n",
        "#         min_word = unique_words[j]\n",
        "\n",
        "#   print(unique_words[i] + ' -> ' + min_word)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "noteable": {
      "last_transaction_id": "9520ea7b-e89e-4a32-b5d9-87cf09379d0e"
    },
    "selected_hardware_size": "small"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
