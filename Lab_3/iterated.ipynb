{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, SimpleRNN\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "num_generations = 4\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw = [\n",
    "    \"a red cat sat on the mat\",\n",
    "    \"the clever dog played with a ball\",\n",
    "    \"one stray cat sat on a ball\",\n",
    "    \"a blue buffalo kicked a small tree\",\n",
    "    \"a big ball flew through our window\"\n",
    "]\n",
    "\n",
    "\n",
    "vocab = set()\n",
    "for datapoint in train_data_raw:\n",
    "  words = datapoint.split(' ')\n",
    "  for word in words:\n",
    "    vocab.add(word)\n",
    "\n",
    "encoding_to_word = {}\n",
    "word_to_encoding = {}\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "    encoding_to_word[i] = word\n",
    "    word_to_encoding[word] = i\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "sentence_size = len(train_data_raw[0].split(' '))\n",
    "data_size = len(train_data_raw)\n",
    "\n",
    "train_data = np.zeros((len(train_data_raw), sentence_size))\n",
    "for i, dp in enumerate(train_data_raw):\n",
    "  words = dp.split(' ')\n",
    "  for j, word in enumerate(words):\n",
    "    train_data[i, j] = word_to_encoding[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    # Define the input shape (assuming each input data point is a sequence of vectors)\n",
    "    input_shape = (data_size, sentence_size)  \n",
    "    output_shape = ((data_size * sentence_size), vocab_size)\n",
    "\n",
    "    # Define the input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    flattened_input = tf.keras.layers.Flatten()(input_layer)\n",
    "\n",
    "    # Add a recurrent layer (SimpleRNN) for sequence processing\n",
    "    # rnn_layer = SimpleRNN(units=64, activation='relu')(flattened_input)\n",
    "    mid_layer = Dense(64, activation='linear')(flattened_input)\n",
    "\n",
    "    # Add a Dense layer with softmax activation for the output\n",
    "    output_layer = Dense(data_size * sentence_size * vocab_size, activation='softmax')(mid_layer)\n",
    "\n",
    "    # Reshape the output to the desired 2D shape\n",
    "    output_layer = tf.keras.layers.Reshape(output_shape)(output_layer)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model with cross-entropy loss and an optimizer (e.g., Adam)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "    # Print the model summary\n",
    "    # model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(dataset_encoding):\n",
    "    label = np.zeros((data_size, sentence_size, vocab_size))\n",
    "    for i, dp in enumerate(dataset_encoding):\n",
    "        for j, word in enumerate(dp):\n",
    "            label[i, j, int(word)] = 1\n",
    "    return label.reshape(((data_size * sentence_size), vocab_size))\n",
    "\n",
    "def train_model(model, input, labels, epochs):\n",
    "    model.fit(np.array([input]), np.array([labels]), epochs=epochs, verbose=0)\n",
    "\n",
    "def get_prediction(model, input):\n",
    "    out = np.array(model(np.array([input])))[0]\n",
    "    out = out.reshape((data_size, sentence_size, vocab_size))\n",
    "    return np.argmax(out, axis=2)\n",
    "\n",
    "def get_sentence(prediction):\n",
    "    sentence = \"\"\n",
    "    for i in range(data_size):\n",
    "        for j in range(sentence_size):\n",
    "            sentence += encoding_to_word[prediction[i, j]] + \" \"\n",
    "        sentence += \"\\n\"\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterated_learning(epochs):\n",
    "    label = create_label(train_data)\n",
    "    last_sent = \"\"\n",
    "\n",
    "    for _ in range(num_generations):\n",
    "        model = create_model()\n",
    "        train_model(model, train_data, label, epochs)\n",
    "\n",
    "        prediction = get_prediction(model, train_data)\n",
    "        label = create_label(prediction)\n",
    "        \n",
    "        last_sent = get_sentence(prediction)\n",
    "\n",
    "    print(\"Epochs : \" + str(epochs))\n",
    "    print(last_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 1\n",
      "tree on red dog tree blue flew \n",
      "kicked red cat mat big through red \n",
      "window sat the with big red stray \n",
      "blue ball flew through tree cat buffalo \n",
      "blue kicked the dog stray our buffalo \n",
      "\n",
      "Epochs : 5\n",
      "cat mat the dog clever red window \n",
      "window mat mat blue dog tree big \n",
      "with played stray dog played the ball \n",
      "through one a dog a with one \n",
      "the flew sat through blue tree red \n",
      "\n",
      "Epochs : 10\n",
      "red the cat the small the window \n",
      "the clever tree played flew one ball \n",
      "one stray blue sat played a ball \n",
      "a our buffalo tree a small blue \n",
      "blue big ball flew through our window \n",
      "\n",
      "Epochs : 15\n",
      "a red cat sat on the mat \n",
      "the clever dog played with a ball \n",
      "one stray flew sat on a ball \n",
      "a blue buffalo kicked a small tree \n",
      "a big ball flew through our window \n",
      "\n",
      "Epochs : 50\n",
      "a red cat sat on the mat \n",
      "the clever dog played with a ball \n",
      "one stray cat sat on a ball \n",
      "a blue buffalo kicked a small tree \n",
      "a big ball flew through our window \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_list = [1, 5, 10, 15, 50]\n",
    "for epoch in epoch_list:\n",
    "    iterated_learning(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
